{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_train = pd.read_csv('./data/grammar_train.csv')\n",
    "grammar_check = pd.read_csv('./data/grammar_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = grammar_train['correct_sentence'].values\n",
    "predicts = grammar_train['sentence_with_a_mistake'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F_score(ground_truth, predicts, originals):\n",
    "    \"\"\"\n",
    "    param: ground_truth: list of str: correct sentence\n",
    "    param: predicts: list of str:  predicts\n",
    "    param: originals: list of str: input sentence\n",
    "    \"\"\"\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for y, pred, original in zip(ground_truth, predicts, originals):\n",
    "        if pred == y:\n",
    "            TP += 1\n",
    "        elif pred == original:\n",
    "            FN += 2\n",
    "        else:\n",
    "            FP += 30\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 2*(precision*recall)/(precision+recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06976744186046512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_F_score(y, predicts, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stopwords-ru.txt') as F:\n",
    "    stop_words = F.read()\n",
    "stop_words = stop_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sequences(original_sequences, predictions):\n",
    "    result = []\n",
    "    for sequence, pred in zip(original_sequences, predictions):\n",
    "        if pred == 0:\n",
    "            tcya_index = sequence.find('тся')\n",
    "            ticya_index = sequence.find('ться')\n",
    "            if tcya_index != -1 and ticya_index == -1:\n",
    "                sequence = sequence[:tcya_index] + 'ться' + sequence[tcya_index + 3:]\n",
    "            if tcya_index == -1 and ticya_index != -1:\n",
    "                sequence = sequence[:tcya_index] + 'тся' + sequence[tcya_index + 4:]\n",
    "        result.append(sequence)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(pred, threshold):\n",
    "    predict_tf = pred < threshold\n",
    "    predict = transform_sequences(test_data, predict_tf)\n",
    "    ground_truth = transform_sequences(test_data, test_y)\n",
    "    res = get_F_score(ground_truth, predict, test_data)\n",
    "    return res, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./grammar_example_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_y, test_y = train_test_split(data.x, data.y, test_size=0.1, random_state=42,\n",
    "                                                         shuffle=True, stratify=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(params):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        analyzer=params['analyzer'], \n",
    "        ngram_range=(params['range_min'], params['range_max']),\n",
    "        min_df=params['min_df'],\n",
    "        stop_words=stop_words\n",
    "    )\n",
    "    lr = LogisticRegression(\n",
    "        solver='liblinear',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=1,\n",
    "    )\n",
    "    return Pipeline([('tfidf', tfidf), ('lr', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'analyzer': 'word',\n",
    "    'range_min': 1,\n",
    "    'range_max': 2,\n",
    "    'min_df': 5,\n",
    "}\n",
    "model = generate_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,...alty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_proba(test_data)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6324678131464386, 0.894736842105263)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for threshold in np.linspace(0, 1, 20):\n",
    "    result.append(scoring(predict, threshold))\n",
    "max(result, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_spalling']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'model_spalling')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
